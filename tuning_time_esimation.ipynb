{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe0fa0-725b-44a5-a4d9-ff6d08573dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import sys\n",
    "from scipy import interpolate, signal, linalg, spatial\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import combinations, product\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel, delayed, pool\n",
    "from IPython.display import clear_output, HTML\n",
    "from IPython.core.debugger import set_trace\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from graph_metrics import laplacian_keigv_similarity, l2_distance\n",
    "from utils import place_field_correlation, calc_spike_similarity_cuda, coords2phi, plot_coords_on_circle\n",
    "\n",
    "N_CPU = cpu_count()\n",
    "TOY_DATASET = False "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7917e1-23ff-4cff-bbf8-56281b753e3e",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "Frame rate is ~21 FPS. \n",
    "It takes ~10 min to learn. \n",
    "It is ~12600 frames. \n",
    "To capture learning our timeframe should be several times shorter than 10 min. \n",
    "1k frames for time-window. \n",
    "Kernel size should represent Hebbian rule temporal, somehow, so there is no need to make it large!\n",
    "\n",
    "***Idea:\n",
    "Check intrinsic dimension once again, reduce dimensionality, consider connectivity matrix in reduced space?***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383dc75c-39dc-4ed0-9fac-0a6943c5bd6e",
   "metadata": {},
   "source": [
    "# Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b548c-a9e1-455f-b91d-bac5a8193d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "track = 'Circle'\n",
    "mouse = 22\n",
    "day = 1 \n",
    "trim0=1500\n",
    "trim1=100\n",
    "root = 'data'\n",
    "\n",
    "# def load_dataset(root, mouse=22, day=1, track='Circle', trim0=1500, trim1=100):\n",
    "\n",
    "#     '''\n",
    "#     Loading dataset of cells activity for \n",
    "#     mouse: int [22,23,24]\n",
    "#     day: [1,2,3]\n",
    "#     track: ['Circle', 'Holy']\n",
    "#     trim0: trim values from the beginning\n",
    "#     trim1: trim values from the end\n",
    "#     '''\n",
    "\n",
    "calcium_df = pd.read_csv(os.path.join(root,f\"{track}/data/CA1_{mouse}_{day}D_initial_data.csv\"), \n",
    "                         index_col=0)\n",
    "spikes_df = pd.read_csv(os.path.join(root,f\"{track}/spikes/CA1_{mouse}_{day}D_initial_data_spikes.csv\"), \n",
    "                        index_col=0)\n",
    "rears_events = pd.read_csv(os.path.join(root,f'CA1_22-25_rears/CA1_{mouse}_{day}D_rears_from_npz.csv'), \n",
    "                           index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b8544e-a9f0-4a96-a6e6-db4e8a7370e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cadata = calcium_df.iloc[:,7:][trim0:-trim1].T.values # [n_neurons, T] \n",
    "spdata = spikes_df.iloc[:,1:][trim0:-trim1].T.values # [n_neurons, T]\n",
    "time = calcium_df['time_s'][trim0:-trim1].values # 21 FPS\n",
    "rears_events = rears_events[trim0:-trim1]\n",
    "\n",
    "rear_times = rears_events['time_s'].values\n",
    "rears_indicators = rears_events['rear_1_outward_-1_inward'].values\n",
    "\n",
    "cells_with_spikes = np.sum(spdata, axis = 1) > 1.\n",
    "\n",
    "spdata = spdata[cells_with_spikes]\n",
    "cadata = cadata[cells_with_spikes]\n",
    "spdata_bool = spdata.astype(bool)\n",
    "cadata_ = StandardScaler().fit_transform(cadata.T).T\n",
    "\n",
    "N, T = spdata.shape\n",
    "neurons = np.arange(N)\n",
    "\n",
    "###########\n",
    "# TARGETS #\n",
    "###########\n",
    "coords = calcium_df[['x','y']][trim0:-trim1].values\n",
    "coords -= coords.mean(0)[None,:]\n",
    "minmax_scaler = MinMaxScaler((-1,1))\n",
    "coords_ = minmax_scaler.fit_transform(coords)\n",
    "coords_normalized = coords_ / np.linalg.norm(coords_, axis=1)[:,None]\n",
    "\n",
    "phi = np.arctan2(coords_[:,1], coords_[:,0])\n",
    "phi[phi < 0] = 2*np.pi + phi[phi < 0]\n",
    "\n",
    "# speed sign\n",
    "dphi = np.diff(phi, prepend=phi[0])\n",
    "jump_mask = np.abs(dphi) > 6 # jump through breakpoint\n",
    "dphi[jump_mask] = -1 * np.sign(dphi[jump_mask]) * np.abs(dphi[jump_mask] - 2*np.pi)\n",
    "circle_sign = np.sign(dphi)\n",
    "\n",
    "# speed\n",
    "shift = np.diff(coords_, prepend=[coords_[0]], axis=0)\n",
    "speed = np.sqrt((shift**2).sum(1)) * circle_sign\n",
    "speed_ = MinMaxScaler((-1,1)).fit_transform(speed[:,None]).flatten()\n",
    "\n",
    "# acceleration\n",
    "acceleration = np.diff(speed, prepend=speed[0])\n",
    "acceleration_ = MinMaxScaler((0,1)).fit_transform(acceleration[:,None]).flatten()\n",
    "\n",
    "# rears indicators\n",
    "rears_indicators_abs = np.pad(np.abs(rears_indicators), pad_width=(T - rears_indicators.shape[0])//2)\n",
    "phi_ = MinMaxScaler().fit_transform(phi[:,None]).flatten()\n",
    "\n",
    "targets = {\n",
    "    'x': coords_[:,0],\n",
    "    'y': coords_[:,1],\n",
    "    'v': speed_,\n",
    "    'a': acceleration_,\n",
    "    'phi': phi_\n",
    "}\n",
    "\n",
    "# return targets\n",
    "\n",
    "plt.scatter(targets['x'], targets['y'], c=phi_)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac11e3-4aa8-41df-a9c8-24684655c2eb",
   "metadata": {},
   "source": [
    "# Create toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5c4fd9-646c-4d22-a5af-bf9cb3080aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOY_DATASET = True\n",
    "\n",
    "# toy_steps_per_round = 1000\n",
    "# dphi = 2*np.pi/toy_steps_per_round\n",
    "# toy_neurons_per_place = 10\n",
    "# toy_n_places = 4\n",
    "# toy_timesteps = 5000\n",
    "# toy_spdata = np.zeros((toy_n_places*toy_neurons_per_place, toy_timesteps))\n",
    "# toy_phi = []\n",
    "\n",
    "# for i in range(toy_timesteps):\n",
    "#     j = i%(toy_steps_per_round) # index within round \n",
    "#     step = dphi*j\n",
    "#     toy_phi.append(step)\n",
    "#     # number of place\n",
    "#     k = int(j//(toy_steps_per_round//toy_n_places))\n",
    "    \n",
    "#     if i%25==0 and j%(toy_steps_per_round//toy_n_places) != 0:\n",
    "#         for m,random_offset in enumerate(np.random.choice(np.arange(-3,4), size=toy_neurons_per_place)):\n",
    "#             toy_spdata[min(toy_neurons_per_place*toy_n_places - 1, (k*toy_neurons_per_place)+m),\n",
    "#                        i+random_offset] = 1.\n",
    "    \n",
    "# toy_phi = np.array(toy_phi) #- np.pi\n",
    "# x_toy = np.cos(toy_phi)\n",
    "# y_toy = np.sin(toy_phi)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(x_toy, y_toy, c=toy_phi)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172ea891-5e0e-4183-9f52-3f6d6c872e1e",
   "metadata": {},
   "source": [
    "# Set hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f59b68-300a-4c1b-b778-cdddc3d667ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1000\n",
    "kernel_size=49\n",
    "start,end = 0, T-dt\n",
    "SYGMA = 5\n",
    "kernel_type = 'gaussian'\n",
    "# T_RISE = 10\n",
    "# T_OFF = 40\n",
    "bins=25\n",
    "\n",
    "REMAKE_CORR = False\n",
    "REMAKE_PF = False\n",
    "SELECT_NEURONS = False\n",
    "\n",
    "if SELECT_NEURONS:\n",
    "    neurons_selected = selective_cells\n",
    "else:\n",
    "    neurons_selected = neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f1bc18-f47c-443c-b9ce-b2329aa77145",
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_type == 'gaussian':\n",
    "    assert kernel_size%2==1\n",
    "    if SYGMA is None:\n",
    "        SYGMA = kernel_size//7\n",
    "    sp = signal.gaussian(M=kernel_size, std=SYGMA)\n",
    "\n",
    "elif kernel_type == 'exponential':\n",
    "    def spike_form(t):\n",
    "        return (1-np.exp(-t/T_RISE))*np.exp(-t/T_OFF)\n",
    "    x = np.linspace(0, kernel_size, num = kernel_size)\n",
    "    sp = spike_form(x)[::-1].copy()\n",
    "\n",
    "sp_torch = torch.tensor(sp).float().cuda()\n",
    "sp_torch_batch = sp_torch.unsqueeze(0).unsqueeze(0)\n",
    "spdata_torch = torch.tensor(spdata).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623c5125-1111-4678-b177-dcfcf60a0248",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(spdata.flatten(), bins=50)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3309a8b5-b2ac-4f57-93e6-462c1909bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_torch = torch.conv1d(input=spdata_torch.unsqueeze(1), weight=sp_torch_batch, padding=kernel_size//2).squeeze(1)#[:,:dt]\n",
    "# vis = []\n",
    "# for i in range(20):\n",
    "#     vis.append(result_torch[neurons_selected, dt*i:dt*(i+1)].detach().cpu().numpy())\n",
    "#     vis.append(np.ones((1,dt))*10)\n",
    "# vis = np.vstack(vis)\n",
    "# plt.figure(figsize=(50,20), dpi=200)\n",
    "# plt.imshow(vis)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe633141-f4b0-47d0-b88d-f7947c1a34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spdata_convolved = result_torch.detach().cpu().numpy()\n",
    "spdata_convolved_ = spdata_convolved/spdata_convolved.max() #MinMaxScaler().fit_transform(spdata_convolved.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f83019e-600d-4fb6-a102-9e801b434190",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(spdata_convolved_.flatten(), bins=50)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0121b0c-c61c-4f4c-bb4e-3caf0f2cb1e2",
   "metadata": {},
   "source": [
    "# Create place-field and convolved spike correlation maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafae972-709a-483e-b269-3a38d01291d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'TOY' if TOY_DATASET else f'Circle_M{mouse}_D{day}'\n",
    "\n",
    "if kernel_type == 'exponential':\n",
    "    corr_dir = f'./experimental_data/corrmap_data/corrmaps_' + name +  f'_dt{dt}_kernel{kernel_size}_{kernel_type}_TRISE{T_RISE}_TOFF{T_OFF}'  + \\\n",
    "            (f'_selected_A{ACTIVITY_SELECTIVE_THRESHOLD}_S{STD_SELECTIVE_THRESHOLD}' if SELECT_NEURONS else '')\n",
    "    \n",
    "elif kernel_type == 'gaussian':\n",
    "    corr_dir = f'./experimental_data/corrmap_data/corrmaps_' + name + f'_dt{dt}_kernel{kernel_size}_{kernel_type}_SYGMA{SYGMA}'  + \\\n",
    "            (f'_selected_A{ACTIVITY_SELECTIVE_THRESHOLD}_S{STD_SELECTIVE_THRESHOLD}' if SELECT_NEURONS else '')\n",
    "\n",
    "if os.path.exists(corr_dir):\n",
    "        if REMAKE_CORR:\n",
    "            print('Removing corr_dir?')\n",
    "            answer = input()\n",
    "            if answer == 'yes':\n",
    "                shutil.rmtree(corr_dir)\n",
    "                os.makedirs(corr_dir, exist_ok=True)\n",
    "else:\n",
    "    os.makedirs(corr_dir)\n",
    "    \n",
    "    \n",
    "pf_dir = f'./experimental_data/pf_data/pf_' + name + f'_dt{dt}_hist2d-bins{bins}' + \\\n",
    "            (f'_selected_A{ACTIVITY_SELECTIVE_THRESHOLD}_S{STD_SELECTIVE_THRESHOLD}' if SELECT_NEURONS else '')\n",
    "\n",
    "if os.path.exists(pf_dir):\n",
    "        if REMAKE_PF:\n",
    "            print('Removing pf_dir?')\n",
    "            answer = input()\n",
    "            if answer == 'yes':\n",
    "                shutil.rmtree(pf_dir)\n",
    "                os.makedirs(pf_dir, exist_ok=True)\n",
    "else:\n",
    "    os.makedirs(pf_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c3a156-4ceb-47bb-b8b6-780be7b38120",
   "metadata": {},
   "source": [
    "# Making matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1341e032-ceaf-443a-9089-670af43444fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REMAKE_CORR:\n",
    "    sim_matrices = Parallel(n_jobs=10, verbose=1)(delayed(calc_spike_similarity_cuda)(sp_torch_batch,\n",
    "                                                                                     spdata_torch[neurons_selected,i:i+dt], \n",
    "                                                                                     save=True,\n",
    "                                                                                     corr_dir=corr_dir,\n",
    "                                                                                     i=i) for i in tqdm_notebook(range(start,end)))\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6138347e-0b2c-429d-868f-8b487d6a2f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REMAKE_PF:\n",
    "    pf_paths = Parallel(n_jobs=-1, verbose=1)(delayed(place_field_correlation)(spdata_bool[neurons_selected,i:i+dt], \n",
    "                                                                              coords_[i:i+dt,:],\n",
    "                                                                              save=True,\n",
    "                                                                              pf_dir=pf_dir,\n",
    "                                                                              i=i,\n",
    "                                                                              bins=bins) for i in tqdm_notebook(range(start,end)))\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931207d7-470e-4450-bf2f-b9f6ac76fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_paths = np.array([os.path.join(corr_dir, path) for path in sorted(os.listdir(corr_dir), key=lambda x: int(x.split('.')[0]))])\n",
    "pf_paths = np.array([os.path.join(pf_dir, path) for path in sorted(os.listdir(pf_dir), key=lambda x: int(x.split('.')[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916c334b-2f32-4931-8be4-ee4859ad9c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(corr_paths) == len(pf_paths) and len(corr_paths) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f02101d-c957-425c-b2f4-9a80aede5d91",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e98c3b-27b0-48c4-9394-fdd084b888d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vis= 10\n",
    "dil_vis = 100\n",
    "fig, axes = plt.subplots(ncols=n_vis, nrows=2, figsize=(5*n_vis,10), sharex=True, sharey=True)\n",
    "for i,p1,p2 in zip(range(n_vis), corr_paths[::dil_vis][:n_vis], pf_paths[::dil_vis][:n_vis]):\n",
    "    s = np.load(p1)\n",
    "    p = np.load(p2) # [neurons_selected][:,neurons_selected]\n",
    "    axes[0,i].imshow(s)\n",
    "    axes[1,i].imshow(p) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7679105-72cd-4e13-adcd-456c3c716a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y,y_pred):\n",
    "    mae = np.linalg.norm(y - y_pred, ord=1, axis=1, keepdims=True) / np.linalg.norm(y, ord=1, axis=1, keepdims=True)\n",
    "    return mae.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578814fa-93dc-4b06-9f9b-82edd5927b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pf_metrics(corr_paths, \n",
    "                         pf_paths, \n",
    "                         neurons_selected=None, \n",
    "                         use_nonsinge_nodes=False, \n",
    "                         full_decomposition=True, \n",
    "                         n_jobs=-1):\n",
    "    metrics = {}\n",
    "    \n",
    "    metrics['lap_values'] = Parallel(n_jobs=n_jobs, verbose=1)(delayed(laplacian_keigv_similarity)(p1, \n",
    "                                                                                                    p2, \n",
    "                                                                                                    neurons_selected=neurons_selected,\n",
    "                                                                                                    full_decomposition=full_decomposition) \\\n",
    "                                                    for p1,p2 in tqdm_notebook(zip(corr_paths, pf_paths)))\n",
    "    \n",
    "    metrics['lap_values_random'] = Parallel(n_jobs=n_jobs, verbose=1)(delayed(laplacian_keigv_similarity)(p1, p2, full_decomposition=full_decomposition) \\\n",
    "                                                           for p1,p2 in tqdm_notebook(zip(np.random.choice(corr_paths, size=1000), \n",
    "                                                                                           np.random.choice(pf_paths, size=1000))))\n",
    "\n",
    "    metrics['fro'] = Parallel(n_jobs=-n_jobs, verbose=1)(delayed(l2_distance)(p1, \n",
    "                                                                              p2, \n",
    "                                                                              neurons_selected=neurons_selected, \n",
    "                                                                              use_nonsinge_nodes=use_nonsinge_nodes) \n",
    "                                                         for p1,p2 in tqdm_notebook(zip(corr_paths, pf_paths)))\n",
    "    \n",
    "    metrics['fro_random'] = Parallel(n_jobs=n_jobs, verbose=1)(delayed(l2_distance)(p1, p2) \n",
    "                                                         for p1,p2 in tqdm_notebook(zip(np.random.choice(corr_paths, size=1000), \n",
    "                                                                                       np.random.choice(pf_paths, size=1000))))\n",
    "    clear_output()\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3149cf56-9979-4bd9-80dd-a8033f8635c2",
   "metadata": {},
   "source": [
    "# Metrics by STD threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98003caf-dbbb-49b2-b2ee-e2029b422920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_by_threshold = defaultdict(dict)\n",
    "# stds_thresholds = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.]\n",
    "\n",
    "# fro_random = Parallel(n_jobs=-1, verbose=1)(delayed(l2_distance)(p1, p2) for p1,p2 in tqdm_notebook(zip(np.random.choice(corr_paths, size=1000), \n",
    "#                                                                                                        np.random.choice(pf_paths, size=1000))))\n",
    "# fro_random = np.array(fro_random)\n",
    "# fro_random_mean = fro_random[~np.isnan(fro_random)].mean()\n",
    "\n",
    "# for i,std_thresh in enumerate(stds_thresholds):\n",
    "#     print('neurons selected', len(neurons_selected), f'{i/len(stds_thresholds)}%')\n",
    "#     mask = (stds_sorted < std_thresh)*(total_activity_[neurons_by_std] > 0.05)\n",
    "#     neurons_selected = neurons_by_std[mask]\n",
    "    \n",
    "#     fro = Parallel(n_jobs=-1, verbose=1)(delayed(l2_distance)(p1, \n",
    "#                                                               p2, \n",
    "#                                                               neurons_selected=neurons_selected, \n",
    "#                                                               use_nonsinge_nodes=True) for p1,p2 in tqdm_notebook(zip(corr_paths, pf_paths)))\n",
    "    \n",
    "#     clear_output()\n",
    "    \n",
    "    \n",
    "#     fro = pd.Series(data=fro).fillna(method='ffill').fillna(method='bfill').values\n",
    "\n",
    "#     metrics_by_threshold[std_thresh]['fro'] = fro\n",
    "#     metrics_by_threshold[std_thresh]['neurons_selected'] = neurons_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028b7045-fd0e-462d-8625-abb158378f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cadata_ = StandardScaler().fit_transform(cadata.T)\n",
    "# scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "# mean_mae = []\n",
    "\n",
    "# for i,std_thresh in enumerate(stds_thresholds):\n",
    "#     mask = (stds_sorted < std_thresh)*(total_activity_[neurons_by_std] > 0.05)\n",
    "#     neurons_selected = neurons_by_std[mask]\n",
    "#     est = RegressorChain(Ridge()) # n_jobs=-1\n",
    "#     mean_mae.append(-cross_val_score(est, cadata_[:, neurons_selected], coords_, scoring=scorer, cv=3).mean()) # [1000:3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23797289-484c-43fa-bee1-223f286f1a68",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b193c-7343-49dc-a62d-7f16418d24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = calculate_pf_metrics(corr_paths, pf_paths, neurons_selected=None, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd01ae4-5473-4a63-bd8a-72ff0c41785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post processing\n",
    "for k,v in metrics.items():\n",
    "    if np.isnan(v).any():\n",
    "        series = pd.Series(data=v).fillna(method='ffill').fillna(method='bfill')\n",
    "        metrics[k] = series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c0e673-3743-4c37-8ecf-26baebc12b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lap_values_all = MinMaxScaler().fit_transform(np.concatenate([metrics['lap_values'], metrics['lap_values_random']])[:,None]).flatten()\n",
    "# metrics['lap_values_'] = lap_values_all[:len(metrics['lap_values'])]\n",
    "# metrics['lap_values_random_'] = lap_values_all[len(metrics['lap_values']):]\n",
    "\n",
    "# fro_values_all = MinMaxScaler().fit_transform(np.concatenate([metrics['fro'], metrics['fro_random']])[:,None]).flatten()\n",
    "# metrics['fro_'] = fro_values_all[:len(metrics['fro'])]\n",
    "# metrics['fro_random_'] = fro_values_all[len(metrics['fro']):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092df426-cfe4-4790-b7e5-7e42dfa96d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_dir.split('corrmaps')[1][1:] + f'_hist2d-bins{bins}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19324b4-93af-4e3c-94d1-382107a09b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5),dpi=200)\n",
    "plt.plot(metrics['fro'], label='Frobenius norm')\n",
    "plt.hlines(np.max(metrics['fro_random']), 0, len(metrics['fro']), label='Random Frobenius', alpha=0.3, color='red', linestyle='--')\n",
    "plt.title(corr_dir.split('corrmaps')[1][1:] + f'_hist2d-bins{bins}') \n",
    "plt.xlabel('t')\n",
    "plt.ylabel('Frobenius norm: |S-P|')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bdb76b-db9d-4942-8ddc-faf578b95c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a99c5-2b9d-4090-a1b9-bc349e6b7f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "144895a5-143b-47de-a6fb-1e95081cbe63",
   "metadata": {},
   "source": [
    "# Stable component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57096ac-8743-4bd7-b791-0b303f963c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'TOY' if TOY_DATASET else f'Circle_M{mouse}_D{day}'\n",
    "\n",
    "if kernel_type == 'exponential':\n",
    "    corr_dir_ext = f'./experimental_data/corrmap_data_ext/corrmaps_' + name +  f'_dt{dt}_kernel{kernel_size}_{kernel_type}_TRISE{T_RISE}_TOFF{T_OFF}'  + \\\n",
    "            (f'_selected_A{ACTIVITY_SELECTIVE_THRESHOLD}_S{STD_SELECTIVE_THRESHOLD}' if SELECT_NEURONS else '')\n",
    "    \n",
    "elif kernel_type == 'gaussian':\n",
    "    corr_dir_ext = f'./experimental_data/corrmap_data_ext/corrmaps_' + name + f'_dt{dt}_kernel{kernel_size}_{kernel_type}_SYGMA{SYGMA}'  + \\\n",
    "            (f'_selected_A{ACTIVITY_SELECTIVE_THRESHOLD}_S{STD_SELECTIVE_THRESHOLD}' if SELECT_NEURONS else '')\n",
    "\n",
    "if os.path.exists(corr_dir_ext):\n",
    "        if REMAKE_CORR:\n",
    "            print('Removing corr_dir?')\n",
    "            answer = input()\n",
    "            if answer == 'yes':\n",
    "                shutil.rmtree(corr_dir_ext)\n",
    "                os.makedirs(corr_dir_ext, exist_ok=True)\n",
    "else:\n",
    "    os.makedirs(corr_dir_ext)\n",
    "    \n",
    "    \n",
    "pf_dir_ext = f'./experimental_data/pf_data_ext/pf_' + name + f'_dt{dt}_hist2d-bins{bins}' + \\\n",
    "            (f'_selected_A{ACTIVITY_SELECTIVE_THRESHOLD}_S{STD_SELECTIVE_THRESHOLD}' if SELECT_NEURONS else '')\n",
    "\n",
    "if os.path.exists(pf_dir_ext):\n",
    "        if REMAKE_PF:\n",
    "            print('Removing pf_dir?')\n",
    "            answer = input()\n",
    "            if answer == 'yes':\n",
    "                shutil.rmtree(pf_dir_ext)\n",
    "                os.makedirs(pf_dir_ext, exist_ok=True)\n",
    "else:\n",
    "    os.makedirs(pf_dir_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c5734-fea8-4688-b4e2-8572e89091ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REMAKE_CORR:\n",
    "    _ = Parallel(n_jobs=10, verbose=0)(delayed(calc_spike_similarity_cuda)(sp_torch_batch,\n",
    "                                                                             spdata_torch[neurons_selected,:i+dt], \n",
    "                                                                             save=True,\n",
    "                                                                             corr_dir=corr_dir_ext,\n",
    "                                                                             i=i) for i in tqdm_notebook(range(start,end)))\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae3a74-5147-439d-8ede-6c1aee379f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # is there will be spurious correlations in PF?\n",
    "# if REMAKE_PF:\n",
    "#     pf_paths = Parallel(n_jobs=-1, verbose=1)(delayed(place_field_correlation)(spdata_bool[neurons_selected,:i+dt], \n",
    "#                                                                               coords_[:i+dt,:],\n",
    "#                                                                               save=True,\n",
    "#                                                                               pf_dir=pf_dir_ext,\n",
    "#                                                                               i=i,\n",
    "#                                                                               bins=bins) for i in tqdm_notebook(range(start,end)))\n",
    "#     clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667b76fc-acbe-4c16-92e5-56bec7aa0469",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_ext_paths = np.array([os.path.join(corr_dir_ext, path) for path in sorted(os.listdir(corr_dir_ext), key=lambda x: int(x.split('.')[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282fcebe-b1e4-4490-9612-e8524e491142",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_s_ext = Parallel(n_jobs=-1)(delayed(np.load)(p) for p in tqdm_notebook(corr_ext_paths))\n",
    "A_s_ext = np.stack(A_s_ext, 0).reshape((len(corr_ext_paths),-1))\n",
    "# edge_threshold = 0.2\n",
    "# A_s[A_s < threshold] = 0\n",
    "# A_s = sparse.csr_matrix(A_s)\n",
    "A_s_ext = A_s_ext[:,A_s_ext.sum(0) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8069ca-c8f6-4e33-9375-392a3ea8d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_variance_kernel_size=dt\n",
    "\n",
    "def graphs_variance(A_s):\n",
    "    A_s_mean = A_s.mean(0)\n",
    "    D = np.linalg.norm(A_s - A_s_mean, axis=-1)\n",
    "    return D.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8897dd5d-8e09-41af-a9b4-72d88d09c044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # metric = lambda p1,p2: laplacian_keigv_similarity(p1, p2, neurons_selected=neurons_selected, return_nonsingle=False, normalize=True, k=10)\n",
    "# D_s = Parallel(n_jobs=2, backend='multiprocessing')(delayed(graphs_variance)(A_s[i:i+graph_variance_kernel_size]) \\\n",
    "#                                                   for i in tqdm_notebook(range(len(A_s) - graph_variance_kernel_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085573e-ef71-4f5d-b74f-891ad6f8ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_s = []\n",
    "for i in tqdm_notebook(range(0, len(A_s_ext) - graph_variance_kernel_size, 20)):\n",
    "    D_s.append(graphs_variance(A_s_ext[i:i+graph_variance_kernel_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba38225e-e15c-49cf-8b4b-85ca98ffcfc9",
   "metadata": {},
   "source": [
    "# Random connectivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba04731-37c2-46bc-8a79-40376ee58228",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_random = np.random.randn(N,T)\n",
    "A_s_random = []\n",
    "\n",
    "for i in tqdm_notebook(range(T-dt)):\n",
    "    X_random_dt = X_random[:,:i+dt] - X_random[:,:i+dt].mean(1)[:,None]\n",
    "    S = X_random_dt@X_random_dt.T\n",
    "    X_random_norms = np.linalg.norm(X_random_dt, axis=1)[:,None]\n",
    "    S = S / (X_random_norms@X_random_norms.T + 1e-10)\n",
    "    S[np.diag_indices_from(S)] = 0\n",
    "    A_s_random.append(S)\n",
    "    \n",
    "A_s_random = np.stack(A_s_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92882c1-6671-4269-9f20-121a40354778",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_s_random = []\n",
    "for i in tqdm_notebook(range(0, len(A_s_random) - graph_variance_kernel_size, 20)):\n",
    "    D_s_random.append(graphs_variance(A_s_random[i:i+graph_variance_kernel_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31afc5e8-00e7-4e7d-89e5-9918cc765281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_connectivity(N):\n",
    "    C = np.random.uniform(size=(N,N))\n",
    "    C = C.T@C\n",
    "    C[np.diag_indices_from(C)] = 0\n",
    "    return C/C.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c01d9c-1054-401d-99ec-94b428ea4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_random = graphs_variance(np.concatenate([sim_connectivity(N) for _ in range(graph_variance_kernel_size)]))\n",
    "# D_s_ = MinMaxScaler().fit_transform(np.array(D_s)[:,None])\n",
    "plt.plot(D_s, label='data')\n",
    "plt.xlabel('time-window length')\n",
    "plt.ylabel('L2 variance')\n",
    "plt.title('Circle_M25_D1_dt1000_kernel49_corrmap_gaussian_SYGMA5' + f'_varsize_{graph_variance_kernel_size}_dil20')\n",
    "param = speed_[:len(A_s) - graph_variance_kernel_size:20]\n",
    "param_convolved = np.convolve(param,np.blackman(50),mode='same')\n",
    "param_convolved_ = MinMaxScaler().fit_transform(param_convolved[:,None])\n",
    "# plt.plot(param_convolved_, label='speed', alpha=0.5)\n",
    "plt.plot(D_s_random, label='noise', alpha=0.5)\n",
    "\n",
    "plt.hlines(y=var_random, xmin=0, xmax=len(D_s), linestyle='--', color='r', alpha=0.5, label='random connectivity variance')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
